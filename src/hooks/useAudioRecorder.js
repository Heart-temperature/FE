import { useState, useRef, useCallback } from 'react';

/**
 * ì˜¤ë””ì˜¤ ë…¹ìŒì„ ìœ„í•œ ì»¤ìŠ¤í…€ í›…
 * WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
 */
export const useAudioRecorder = () => {
    const [isRecording, setIsRecording] = useState(false);
    const [error, setError] = useState(null);

    const streamRef = useRef(null);
    const audioContextRef = useRef(null);
    const processorRef = useRef(null);
    const sourceRef = useRef(null);
    const wsRef = useRef(null);

    /**
     * ë…¹ìŒ ì‹œì‘
     * @param {WebSocket} websocket - ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì „ì†¡í•  WebSocket ì—°ê²°
     */
    const startRecording = useCallback(async (websocket) => {
        try {
            setError(null);

            // WebSocket ì—°ê²° í™•ì¸
            if (!websocket || websocket.readyState !== WebSocket.OPEN) {
                throw new Error('WebSocketì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
            }

            wsRef.current = websocket;

            // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    channelCount: 1,
                    sampleRate: 16000,
                    echoCancellation: true,
                    noiseSuppression: true,
                },
            });

            streamRef.current = stream;

            // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (16kHz ìƒ˜í”Œë ˆì´íŠ¸)
            const audioContext = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 16000,
            });

            audioContextRef.current = audioContext;

            // ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ìƒì„±
            const source = audioContext.createMediaStreamSource(stream);
            sourceRef.current = source;

            // ScriptProcessorë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬
            // 4096 ìƒ˜í”Œ ë²„í¼, 1 ì…ë ¥ ì±„ë„, 1 ì¶œë ¥ ì±„ë„
            const processor = audioContext.createScriptProcessor(4096, 1, 1);
            processorRef.current = processor;

            // ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì‹± ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
            processor.onaudioprocess = (e) => {
                if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
                    return;
                }

                // Float32 ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                const inputData = e.inputBuffer.getChannelData(0);

                // Float32ë¥¼ Int16ìœ¼ë¡œ ë³€í™˜ (AI ì„œë²„ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹)
                const int16Data = new Int16Array(inputData.length);
                for (let i = 0; i < inputData.length; i++) {
                    // -1.0 ~ 1.0 ë²”ìœ„ë¥¼ -32768 ~ 32767ë¡œ ë³€í™˜
                    const s = Math.max(-1, Math.min(1, inputData[i]));
                    int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
                }

                // WebSocketìœ¼ë¡œ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì „ì†¡
                try {
                    wsRef.current.send(int16Data.buffer);
                } catch (err) {
                    console.error('ì˜¤ë””ì˜¤ ì „ì†¡ ì‹¤íŒ¨:', err);
                }
            };

            // ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²°
            source.connect(processor);
            processor.connect(audioContext.destination);

            // ë…¹ìŒ ì‹œì‘ ë©”ì‹œì§€ ì „ì†¡
            websocket.send(
                JSON.stringify({
                    type: 'start',
                    lang: 'ko',
                })
            );

            setIsRecording(true);
            console.log('ğŸ¤ ë…¹ìŒ ì‹œì‘');
        } catch (err) {
            console.error('ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:', err);
            setError(err.message);
            throw err;
        }
    }, []);

    /**
     * ë…¹ìŒ ì¤‘ì§€
     */
    const stopRecording = useCallback(() => {
        try {
            // ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
            if (streamRef.current) {
                streamRef.current.getTracks().forEach((track) => track.stop());
                streamRef.current = null;
            }

            // ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²° í•´ì œ
            if (processorRef.current) {
                processorRef.current.disconnect();
                processorRef.current.onaudioprocess = null;
                processorRef.current = null;
            }

            if (sourceRef.current) {
                sourceRef.current.disconnect();
                sourceRef.current = null;
            }

            // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¢…ë£Œ
            if (audioContextRef.current) {
                audioContextRef.current.close();
                audioContextRef.current = null;
            }

            // ë…¹ìŒ ì¤‘ì§€ ë©”ì‹œì§€ ì „ì†¡
            if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
                wsRef.current.send(
                    JSON.stringify({
                        type: 'stop',
                    })
                );
            }

            wsRef.current = null;
            setIsRecording(false);
            console.log('â¹ï¸ ë…¹ìŒ ì¤‘ì§€');
        } catch (err) {
            console.error('ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜:', err);
            setError(err.message);
        }
    }, []);

    /**
     * í† ê¸€ ë…¹ìŒ (ì‹œì‘/ì¤‘ì§€)
     */
    const toggleRecording = useCallback(
        async (websocket) => {
            if (isRecording) {
                stopRecording();
            } else {
                await startRecording(websocket);
            }
        },
        [isRecording, startRecording, stopRecording]
    );

    return {
        isRecording,
        error,
        startRecording,
        stopRecording,
        toggleRecording,
    };
};

export default useAudioRecorder;

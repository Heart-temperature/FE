import React, { useState, useEffect, useRef } from 'react';
import { Button, Flex, Text, VStack, Box, Image, Divider } from '@chakra-ui/react';
import { motion, AnimatePresence } from 'framer-motion';
import { useNavigate, useLocation } from 'react-router-dom';

import DajeongLogo from '../../assets/image.png';
import DabokVideo from '../../video/dabok.webm';
import DajeongVideo from '../../video/dajeung.webm';
import useAppSettings from '../../hooks/useAppSettings';

import { endCall, startCall } from '../../api/callAPI';
import { getAiSocket } from '../../api/aiSocket';

const MotionBox = motion(Flex);
const MotionText = motion(Text);

// ìƒíƒœ ì •ì˜
const STATES = {
    IDLE: 'idle', // ëŒ€ê¸° ì¤‘
    RECORDING: 'recording', // ğŸ¤ ë…¹ìŒ ì¤‘...
    SILENCE_DETECTING: 'silence_detecting', // â¸ï¸ ì¹¨ë¬µ ê°ì§€ ì¤‘...
    SENDING: 'sending', // ğŸ“¤ ì „ì†¡ ì¤‘...
    AI_THINKING: 'ai_thinking', // ğŸ¤– AI ìƒê° ì¤‘...
    AI_SPEAKING: 'ai_speaking', // ğŸ¤– AI ë§í•˜ëŠ” ì¤‘
};

// ìƒíƒœë³„ í‘œì‹œ í…ìŠ¤íŠ¸
const STATE_LABELS = {
    [STATES.IDLE]: 'ëŒ€ê¸° ì¤‘',
    [STATES.RECORDING]: 'ğŸ¤ ë…¹ìŒ ì¤‘...',
    [STATES.SILENCE_DETECTING]: 'â¸ï¸ ì¹¨ë¬µ ê°ì§€ ì¤‘...',
    [STATES.SENDING]: 'ğŸ“¤ ì „ì†¡ ì¤‘...',
    [STATES.AI_THINKING]: 'ğŸ¤– AI ìƒê° ì¤‘...',
    [STATES.AI_SPEAKING]: 'ğŸ¤– AI ë§í•˜ëŠ” ì¤‘',
};

// ìŒì„± ê°ì§€ ì„¤ì •
const VOICE_CONFIG = {
    VOICE_THRESHOLD: 0.01, // ìŒì„±ìœ¼ë¡œ ì¸ì‹í•  ìµœì†Œ ë³¼ë¥¨
    SILENCE_THRESHOLD: 0.005, // ì¹¨ë¬µìœ¼ë¡œ ì¸ì‹í•  ìµœëŒ€ ë³¼ë¥¨
    SILENCE_DURATION: 1000, // ì¹¨ë¬µ ì§€ì† ì‹œê°„ (ms)
    SAMPLE_RATE: 16000, // ìƒ˜í”Œë§ ë ˆì´íŠ¸
};

export default function CallPage() {
    const navigate = useNavigate();
    const location = useLocation();

    const { fontSizeLevel, setFontSizeLevel, isHighContrast, toggleHighContrast, fs, callBtnH } = useAppSettings();

    // ìƒíƒœ ê´€ë¦¬
    const [state, setState] = useState(STATES.IDLE);
    const [currentSubtitle, setCurrentSubtitle] = useState('ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?');

    // Refs
    const videoRef = useRef(null);
    const audioContextRef = useRef(null);
    const mediaStreamRef = useRef(null);
    const analyserRef = useRef(null);
    const mediaRecorderRef = useRef(null);
    const audioChunksRef = useRef([]);
    const silenceTimerRef = useRef(null);
    const audioElementRef = useRef(null);

    // ì „ë‹¬ë°›ì€ ìºë¦­í„° ì •ë³´
    const character = location.state?.character || {
        name: 'ë‹¤ì •ì´',
        characterType: 'dajeong',
        color: '#2196F3',
    };

    useEffect(() => {
        if (location.state) {
            const { character, politeness } = location.state;
            // í†µí™” ì‹œì‘ API í˜¸ì¶œ
            startCall(character, politeness);
        }
    }, [location.state]);

    // ë¹„ë””ì˜¤ ì¬ìƒ ì œì–´
    useEffect(() => {
        if (!videoRef.current) return;

        if (state === STATES.AI_SPEAKING) {
            videoRef.current.play().catch((e) => {
                console.log('Video play failed:', e);
            });
        } else {
            videoRef.current.pause();
        }
    }, [state]);

    // ë§ˆì´í¬ ì´ˆê¸°í™” ë° ìŒì„± ê°ì§€ ì‹œì‘
    useEffect(() => {
        let animationFrameId;

        const initMicrophone = async () => {
            try {
                // ë§ˆì´í¬ ì ‘ê·¼
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: VOICE_CONFIG.SAMPLE_RATE,
                    },
                });
                mediaStreamRef.current = stream;

                // AudioContext ìƒì„±
                audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: VOICE_CONFIG.SAMPLE_RATE,
                });
                const audioContext = audioContextRef.current;

                // Analyser ìƒì„± (ìŒì„± ë ˆë²¨ ê°ì§€)
                const analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                analyserRef.current = analyser;

                const source = audioContext.createMediaStreamSource(stream);
                source.connect(analyser);

                // MediaRecorder ìƒì„±
                mediaRecorderRef.current = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus',
                });

                mediaRecorderRef.current.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunksRef.current.push(event.data);
                    }
                };

                mediaRecorderRef.current.onstop = () => {
                    sendAudioToServer();
                };

                // ìŒì„± ë ˆë²¨ ê°ì§€ ë£¨í”„
                const detectVoice = () => {
                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);
                    analyser.getByteTimeDomainData(dataArray);

                    // ìŒì„± ë ˆë²¨ ê³„ì‚° (RMS)
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        const normalized = (dataArray[i] - 128) / 128;
                        sum += normalized * normalized;
                    }
                    const rms = Math.sqrt(sum / bufferLength);

                    // ìƒíƒœë³„ ì²˜ë¦¬
                    if (state === STATES.IDLE) {
                        // ëŒ€ê¸° ì¤‘: ìŒì„± ê°ì§€ ì‹œ ë…¹ìŒ ì‹œì‘
                        if (rms > VOICE_CONFIG.VOICE_THRESHOLD) {
                            startRecording();
                        }
                    } else if (state === STATES.RECORDING) {
                        // ë…¹ìŒ ì¤‘: ì¹¨ë¬µ ê°ì§€
                        if (rms < VOICE_CONFIG.SILENCE_THRESHOLD) {
                            startSilenceDetection();
                        } else {
                            // ìŒì„±ì´ ë‹¤ì‹œ ê°ì§€ë˜ë©´ ì¹¨ë¬µ íƒ€ì´ë¨¸ ì·¨ì†Œ
                            if (silenceTimerRef.current) {
                                clearTimeout(silenceTimerRef.current);
                                silenceTimerRef.current = null;
                                setState(STATES.RECORDING);
                            }
                        }
                    } else if (state === STATES.SILENCE_DETECTING) {
                        // ì¹¨ë¬µ ê°ì§€ ì¤‘: ìŒì„±ì´ ë‹¤ì‹œ ê°ì§€ë˜ë©´ ë…¹ìŒìœ¼ë¡œ ë³µê·€
                        if (rms > VOICE_CONFIG.VOICE_THRESHOLD) {
                            if (silenceTimerRef.current) {
                                clearTimeout(silenceTimerRef.current);
                                silenceTimerRef.current = null;
                            }
                            setState(STATES.RECORDING);
                        }
                    }

                    animationFrameId = requestAnimationFrame(detectVoice);
                };

                detectVoice();
            } catch (error) {
                console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', error);
                setCurrentSubtitle('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
            }
        };

        initMicrophone();

        return () => {
            // Cleanup
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
            }
            if (mediaStreamRef.current) {
                mediaStreamRef.current.getTracks().forEach((track) => track.stop());
            }
            if (audioContextRef.current) {
                audioContextRef.current.close();
            }
            if (silenceTimerRef.current) {
                clearTimeout(silenceTimerRef.current);
            }
        };
    }, [state]);

    // ë…¹ìŒ ì‹œì‘
    const startRecording = () => {
        console.log('ğŸ¤ ë…¹ìŒ ì‹œì‘');
        setState(STATES.RECORDING);
        setCurrentSubtitle('ë“£ê³  ìˆìŠµë‹ˆë‹¤...');

        audioChunksRef.current = [];
        mediaRecorderRef.current.start();

        // "start" ë©”ì‹œì§€ ì „ì†¡
        const socket = getAiSocket();
        if (socket && socket.readyState === WebSocket.OPEN) {
            socket.send(JSON.stringify({ type: 'start' }));
        }
    };

    // ì¹¨ë¬µ ê°ì§€ ì‹œì‘
    const startSilenceDetection = () => {
        if (state !== STATES.RECORDING) return;
        if (silenceTimerRef.current) return;

        setState(STATES.SILENCE_DETECTING);

        silenceTimerRef.current = setTimeout(() => {
            console.log('â¸ï¸ ì¹¨ë¬µ ì§€ì† -> ë…¹ìŒ ì¢…ë£Œ');
            stopRecording();
        }, VOICE_CONFIG.SILENCE_DURATION);
    };

    // ë…¹ìŒ ì¢…ë£Œ ë° ì „ì†¡
    const stopRecording = () => {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
            setState(STATES.SENDING);
            setCurrentSubtitle('ì „ì†¡ ì¤‘...');
            mediaRecorderRef.current.stop();
        }

        if (silenceTimerRef.current) {
            clearTimeout(silenceTimerRef.current);
            silenceTimerRef.current = null;
        }
    };

    // ì˜¤ë””ì˜¤ ì„œë²„ë¡œ ì „ì†¡
    const sendAudioToServer = async () => {
        console.log('ğŸ“¤ ì˜¤ë””ì˜¤ ì „ì†¡');

        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm;codecs=opus' });
        audioChunksRef.current = [];

        const socket = getAiSocket();
        if (socket && socket.readyState === WebSocket.OPEN) {
            // "stop" ë©”ì‹œì§€ ì „ì†¡
            socket.send(JSON.stringify({ type: 'stop' }));

            // ì˜¤ë””ì˜¤ Blob ì „ì†¡
            socket.send(audioBlob);

            setState(STATES.AI_THINKING);
            setCurrentSubtitle('AIê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤...');
        }
    };

    // WebSocket ë©”ì‹œì§€ ì²˜ë¦¬
    useEffect(() => {
        const socket = getAiSocket();
        if (!socket) return;

        socket.onmessage = async (event) => {
            const data = event.data;

            // ğŸ§ ì˜¤ë””ì˜¤ Blob ë©”ì‹œì§€ ì²˜ë¦¬
            if (data instanceof Blob) {
                console.log('ğŸµ AI ì˜¤ë””ì˜¤ Blob ìˆ˜ì‹ :', data);
                playAiAudio(data);
                return;
            }

            // ğŸ“ JSON í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
            try {
                const msg = JSON.parse(data);
                console.log('ğŸ“© AI JSON ë©”ì‹œì§€ ìˆ˜ì‹ :', msg);

                if (msg.type === 'ended') {
                    // AIê°€ ì‘ë‹µì„ ì™„ë£Œí–ˆìŒì„ ì•Œë¦¼
                    console.log('âœ… AI ì‘ë‹µ ì™„ë£Œ');
                } else if (msg.message) {
                    // ìë§‰ í‘œì‹œ
                    setCurrentSubtitle(msg.message);
                }
            } catch (err) {
                console.warn('âš  JSON íŒŒì‹± ì‹¤íŒ¨ ë©”ì‹œì§€:', data);
            }
        };
    }, []);

    // AI ì˜¤ë””ì˜¤ ì¬ìƒ
    const playAiAudio = async (audioBlob) => {
        setState(STATES.AI_SPEAKING);
        setCurrentSubtitle('AIê°€ ë§í•˜ëŠ” ì¤‘...');

        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);
        audioElementRef.current = audio;

        audio.onended = () => {
            console.log('ğŸ”‡ AI ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ -> ëŒ€ê¸° ì¤‘');
            setState(STATES.IDLE);
            setCurrentSubtitle('ë§ì”€í•´ì£¼ì„¸ìš”!');
            URL.revokeObjectURL(audioUrl);
        };

        audio.onerror = (e) => {
            console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', e);
            setState(STATES.IDLE);
            setCurrentSubtitle('ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
            URL.revokeObjectURL(audioUrl);
        };

        await audio.play();
    };

    const handleEndCall = () => {
        // ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì´ë©´ ì¤‘ì§€
        if (audioElementRef.current) {
            audioElementRef.current.pause();
            audioElementRef.current = null;
        }

        // ë…¹ìŒ ì¤‘ì´ë©´ ì¤‘ì§€
        if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
            mediaRecorderRef.current.stop();
        }

        endCall();
        navigate('/app/home');
    };

    return (
        <Flex minH="100vh" align="center" justify="center" bg={isHighContrast ? '#000000' : 'white'} px={3}>
            {/* ë©”ì¸ ë¡œê·¸ì¸ ì¹´ë“œ */}
            <Box p={{ base: 5, md: 14 }} w="full" maxW="530px">
                <VStack spacing={6} align="stretch">
                    {/* ìºë¦­í„° ì˜ì—­ */}

                    <MotionBox
                        initial={{ scale: 0.8, opacity: 0 }}
                        animate={{ scale: 1, opacity: 1 }}
                        transition={{ duration: 0.5 }}
                        w="100%"
                        h="450px"
                        display="flex"
                        alignItems="center"
                        justifyContent="center"
                        overflow="hidden"
                        borderRadius="15px"
                    >
                        {/* video íƒœê·¸ë¡œ webm ì¬ìƒ ì œì–´ */}

                        <Box
                            as="video"
                            ref={videoRef}
                            src={character.characterType === 'dabok' ? DabokVideo : DajeongVideo}
                            loop
                            muted
                            playsInline
                            w="100%"
                            h="70%"
                            objectFit="cover"
                            onError={(e) => {
                                console.error('Video ë¡œë“œ ì‹¤íŒ¨:', e.target.src);
                            }}
                        />
                    </MotionBox>

                    {/* í˜„ì¬ ìë§‰ */}

                    <Box mt={2}>
                        <AnimatePresence mode="wait">
                            <MotionText
                                key={currentSubtitle}
                                initial={{ opacity: 0, y: 20 }}
                                animate={{ opacity: 1, y: 0 }}
                                exit={{ opacity: 0, y: -20 }}
                                transition={{ duration: 0.3 }}
                                fontSize={fs}
                                fontWeight="700"
                                color={isHighContrast ? '#FFFFFF' : '#000000'}
                                textAlign="center"
                                py={5}
                                borderRadius="15px"
                                minH="90px"
                                display="flex"
                                alignItems="center"
                                justifyContent="center"
                                w="full"
                            >
                                {currentSubtitle}
                            </MotionText>
                        </AnimatePresence>
                    </Box>

                    {/* <Box
                        bg="white"
                        borderRadius="10px"
                        p={3}
                        h="200px"
                        overflowY="auto"
                        mt={4}
                        boxShadow="0 0 10px rgba(0,0,0,0.1)"
                    >
                        {aiMessages.map((m, idx) => (
                            <Text key={idx} color="black" mb={2}>
                                ğŸ‘‰ {m.message || JSON.stringify(m)}
                            </Text>
                        ))}
                    </Box> */}

                    {/* í†µí™” ì¢…ë£Œ ë²„íŠ¼ */}

                    <Button
                        w="full"
                        bg={isHighContrast ? '#FFD700' : '#F44336'}
                        color={isHighContrast ? '#000000' : 'white'}
                        onClick={handleEndCall}
                        fontSize={fs}
                        fontWeight="700"
                        height={callBtnH}
                        borderRadius="15px"
                        border={isHighContrast ? '3px solid white' : 'none'}
                        boxShadow="0 4px 14px rgba(244, 67, 54, 0.3)"
                        mt={2}
                        _hover={{
                            bg: isHighContrast ? '#FFEB3B' : '#D32F2F',

                            transform: 'translateY(-2px)',

                            boxShadow: isHighContrast
                                ? '0 6px 20px rgba(255, 215, 0, 0.4)'
                                : '0 6px 20px rgba(244, 67, 54, 0.4)',
                        }}
                        _active={{
                            bg: isHighContrast ? '#FFC107' : '#C62828',

                            transform: 'translateY(0)',
                        }}
                        transition="all 0.2s"
                    >
                        í†µí™” ì¢…ë£Œ
                    </Button>
                </VStack>
            </Box>
        </Flex>
    );
}

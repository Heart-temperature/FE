import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Button, Flex, Text, VStack, Box, HStack, Badge } from '@chakra-ui/react';
import { motion, AnimatePresence } from 'framer-motion';
import { useNavigate, useLocation } from 'react-router-dom';

import DabokVideo from '../../video/dabok.webm';
import DajeongVideo from '../../video/dajeung.webm';
import useAppSettings from '../../hooks/useAppSettings';

import { endCall, startCall } from '../../api/callAPI';
import { getAiSocket } from '../../api/aiSocket';

const MotionBox = motion(Flex);
const MotionText = motion(Text);

export default function CallPage() {
    const navigate = useNavigate();
    const location = useLocation();

    const { fontSizeLevel, setFontSizeLevel, isHighContrast, toggleHighContrast, fs, callBtnH } = useAppSettings();

    const [isTalking, setIsTalking] = useState(false); // AIê°€ ë§í•˜ëŠ” ì¤‘
    const [isUserTalking, setIsUserTalking] = useState(false); // ì‚¬ìš©ìê°€ ë§í•˜ëŠ” ì¤‘
    const [currentSubtitle, setCurrentSubtitle] = useState('í†µí™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...');
    const [transcriptions, setTranscriptions] = useState([]);
    const [isCallActive, setIsCallActive] = useState(false);

    const videoRef = useRef(null);
    const audioContextRef = useRef(null);
    const audioStreamRef = useRef(null);
    const audioSourceRef = useRef(null);
    const audioProcessorRef = useRef(null);

    // VAD ìƒíƒœ
    const vadStateRef = useRef({
        isSpeaking: false,
        silenceFrames: 0,
        speechFrames: 0,
        preRollBuffer: [],
        isSending: false,
        audioChunks: []
    });

    // ì˜¤ë””ì˜¤ ìˆ˜ì‹  ë²„í¼
    const audioBufferRef = useRef(null);
    const isReceivingAudioRef = useRef(false);

    // VAD ì„¤ì •
    const VAD_CONFIG = {
        frameSize: 4096,
        sampleRate: 16000,
        preRollDuration: 0.5,
        preRollFrames: Math.ceil(16000 * 0.5 / 4096),
        energyThreshold: 0.01,
        speechStartFrames: 3,
        silenceEndFrames: 15,
        minSpeechFrames: 5
    };

    // ì „ë‹¬ë°›ì€ ìºë¦­í„° ì •ë³´
    const character = location.state?.character || {
        name: 'ë‹¤ì •ì´',
        characterType: 'dajeong',
        color: '#2196F3',
    };

    const politeness = location.state?.politeness || 'jondae';

    // ì˜¤ë””ì˜¤ ì¬ìƒ í•¨ìˆ˜
    const playAudio = useCallback(async (audioData) => {
        try {
            const arrayBuffer = audioData instanceof Blob ? await audioData.arrayBuffer() :
                (audioData instanceof ArrayBuffer ? audioData : audioData.buffer);
            const size = arrayBuffer.byteLength;
            console.log(`ğŸµ ì¬ìƒ ì‹œì‘: ${size} bytes`);

            if (!audioContextRef.current) {
                audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });
            }

            if (audioContextRef.current.state === 'suspended') {
                await audioContextRef.current.resume();
                console.log(`ğŸ”Š AudioContext ì¬ê°œë¨`);
            }

            if (arrayBuffer.byteLength < 2) {
                console.warn(`âš ï¸ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë„ˆë¬´ ì‘ìŒ: ${arrayBuffer.byteLength} bytes`);
                return;
            }

            const audioDataInt16 = new Int16Array(arrayBuffer);
            const float32Array = new Float32Array(audioDataInt16.length);

            for (let i = 0; i < audioDataInt16.length; i++) {
                float32Array[i] = audioDataInt16[i] / 32768.0;
            }

            const audioBuffer = audioContextRef.current.createBuffer(1, float32Array.length, 16000);
            audioBuffer.getChannelData(0).set(float32Array);

            const source = audioContextRef.current.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContextRef.current.destination);

            source.onended = () => {
                console.log(`âœ… ì¬ìƒ ì™„ë£Œ (${audioBuffer.duration.toFixed(2)}ì´ˆ)`);
                setIsTalking(false);
            };

            source.start(0);
            console.log(`â–¶ï¸ ì¬ìƒ ì‹œì‘ë¨ (${audioBuffer.duration.toFixed(2)}ì´ˆ)`);
            setIsTalking(true);
        } catch (error) {
            console.error('âŒ ì¬ìƒ ì˜¤ë¥˜:', error);
        }
    }, []);

    // WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬
    const handleMessage = useCallback((data) => {
        console.log(`ğŸ“¨ ìˆ˜ì‹ : ${data.type || data.event || 'unknown'}`, data);

        switch (data.type || data.event) {
            case 'start':
                console.log(`ğŸ“ í†µí™” ì‹œì‘: ${data.message || 'í†µí™” ê±°ëŠ” ì¤‘...'}`);
                setCurrentSubtitle(data.message || 'í†µí™” ê±°ëŠ” ì¤‘...');
                break;
            case 'system':
                console.log(`ğŸ’¬ ì‹œìŠ¤í…œ: ${data.message || ''}`);
                break;
            case 'ready':
                if (data.event === 'start') {
                    console.log('âœ… ìŒì„± ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ');
                }
                break;
            case 'ended':
                if (data.event === 'stop') {
                    console.log('âœ… ìŒì„± ë…¹ìŒ ì¢…ë£Œ ì™„ë£Œ');
                }
                break;
            case 'status':
                console.log(`ğŸ“Š ìƒíƒœ: ${data.message}`);
                setCurrentSubtitle(data.message || '');
                break;
            case 'stt_status':
                console.log(`ğŸ™ï¸ STT ì§„í–‰ ì¤‘: ${data.message}`);
                setCurrentSubtitle('ìŒì„±ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...');
                break;
            case 'tts_start':
                console.log(`ğŸ”Š TTS ì‹œì‘: "${data.text}"`);
                setCurrentSubtitle(data.text || '');
                setIsTalking(true);
                break;
            case 'tts_end':
                console.log(`ğŸ”Š TTS ì¢…ë£Œ`);
                setIsTalking(false);
                break;
            case 'transcription':
                setTranscriptions(prev => [
                    ...prev,
                    { type: 'user', text: data.user_text },
                    { type: 'assistant', text: data.assistant_text }
                ]);
                setCurrentSubtitle(data.assistant_text || '');
                break;
            case 'call_summary':
                console.log('ğŸ“Š í†µí™” ìš”ì•½:', data);
                console.log('ğŸ“Š ê°ì • í†µê³„:', data.emotion_statistics);
                console.log('ğŸ“ ëŒ€í™” ìš”ì•½:', data.conversation_summary);
                // TODO: í†µí™” ìš”ì•½ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê±°ë‚˜ í‘œì‹œ
                setCurrentSubtitle('í†µí™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.');
                break;
            case 'auto_disconnect':
                console.warn(`âš ï¸ ë¹„ì •ìƒ ì¢…ë£Œ: ${data.message}`);
                setCurrentSubtitle('í†µí™”ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.');
                break;
            case 'error':
                console.error(`âŒ ì˜¤ë¥˜: ${data.message}`);
                if (data.message === 'no active session') {
                    console.error('ë…¹ìŒ ì„¸ì…˜ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
                } else {
                    setCurrentSubtitle(`ì˜¤ë¥˜: ${data.message}`);
                }
                break;
        }
    }, []);

    // ìŒì„± ì—ë„ˆì§€ ê³„ì‚°
    const calculateEnergy = (audioData) => {
        let sum = 0;
        for (let i = 0; i < audioData.length; i++) {
            sum += audioData[i] * audioData[i];
        }
        return Math.sqrt(sum / audioData.length);
    };

    // ìŒì„± ê°ì§€
    const detectSpeech = (audioData) => {
        const energy = calculateEnergy(audioData);
        return energy > VAD_CONFIG.energyThreshold;
    };

    // í†µí™” ì‹œì‘ - ë§ˆì´í¬ ì´ˆê¸°í™”
    useEffect(() => {
        const initCall = async () => {
            if (!location.state) return;

            try {
                // 1. í†µí™” ì‹œì‘ API í˜¸ì¶œ
                try {
                    await startCall(character, politeness);
                    console.log('ğŸ“ í†µí™” ì‹œì‘ API í˜¸ì¶œ ì™„ë£Œ');
                } catch (apiError) {
                    console.error('âŒ í†µí™” ì‹œì‘ API ì‹¤íŒ¨:', apiError.message);
                    alert(apiError.message || 'í†µí™”ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
                    navigate('/app/home');
                    return;
                }

                // 2. ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 16000
                    }
                });
                console.log('ğŸ¤ ë§ˆì´í¬ íšë“');

                if (!audioContextRef.current) {
                    audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 16000
                    });
                }

                await new Promise(resolve => setTimeout(resolve, 100));

                const source = audioContextRef.current.createMediaStreamSource(stream);
                const processor = audioContextRef.current.createScriptProcessor(VAD_CONFIG.frameSize, 1, 1);

                // VAD ìƒíƒœ ì´ˆê¸°í™”
                vadStateRef.current = {
                    isSpeaking: false,
                    silenceFrames: 0,
                    speechFrames: 0,
                    preRollBuffer: [],
                    isSending: false,
                    audioChunks: []
                };

                processor.onaudioprocess = (e) => {
                    const socket = getAiSocket();
                    if (!socket || socket.readyState !== WebSocket.OPEN) {
                        return;
                    }

                    const inputData = e.inputBuffer.getChannelData(0);
                    const int16Data = new Int16Array(inputData.length);

                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }

                    // í”„ë¦¬ë¡¤ ë²„í¼ì— ì¶”ê°€
                    vadStateRef.current.preRollBuffer.push(int16Data.buffer);
                    if (vadStateRef.current.preRollBuffer.length > VAD_CONFIG.preRollFrames) {
                        vadStateRef.current.preRollBuffer.shift();
                    }

                    // VADë¡œ ìŒì„± ê°ì§€
                    const hasSpeech = detectSpeech(inputData);
                    if (hasSpeech) {
                        vadStateRef.current.speechFrames++;
                        vadStateRef.current.silenceFrames = 0;

                        // ìŒì„± ì‹œì‘ ê°ì§€
                        if (!vadStateRef.current.isSpeaking && vadStateRef.current.speechFrames >= VAD_CONFIG.speechStartFrames) {
                            vadStateRef.current.isSpeaking = true;
                            vadStateRef.current.isSending = true;
                            vadStateRef.current.audioChunks = [];

                            console.log('ğŸ¤ ìŒì„± ì‹œì‘ ê°ì§€ - start ì´ë²¤íŠ¸ ì „ì†¡');
                            setIsUserTalking(true);

                            socket.send(JSON.stringify({
                                type: 'start',
                                lang: 'ko'
                            }));

                            // í”„ë¦¬ë¡¤ ë²„í¼ í¬í•¨í•´ì„œ ì „ì†¡ ì‹œì‘
                            for (const chunk of vadStateRef.current.preRollBuffer) {
                                vadStateRef.current.audioChunks.push(chunk);
                                socket.send(chunk);
                            }
                        }

                        // ìŒì„± ì¤‘ì´ë©´ ê³„ì† ì „ì†¡
                        if (vadStateRef.current.isSpeaking && vadStateRef.current.isSending) {
                            vadStateRef.current.audioChunks.push(int16Data.buffer);
                            socket.send(int16Data.buffer);
                        }
                    } else {
                        vadStateRef.current.speechFrames = 0;

                        if (vadStateRef.current.isSpeaking) {
                            vadStateRef.current.silenceFrames++;

                            // ë¬´ìŒ ì¤‘ì—ë„ ê³„ì† ì „ì†¡
                            if (vadStateRef.current.isSending) {
                                vadStateRef.current.audioChunks.push(int16Data.buffer);
                                socket.send(int16Data.buffer);
                            }

                            // ìŒì„± ì¢…ë£Œ ê°ì§€
                            if (vadStateRef.current.silenceFrames >= VAD_CONFIG.silenceEndFrames) {
                                if (vadStateRef.current.audioChunks.length >= VAD_CONFIG.minSpeechFrames) {
                                    console.log(`ğŸ¤ ìŒì„± ì¢…ë£Œ ê°ì§€ - stop ì´ë²¤íŠ¸ ì „ì†¡ (${vadStateRef.current.audioChunks.length} í”„ë ˆì„)`);

                                    socket.send(JSON.stringify({
                                        type: 'stop'
                                    }));
                                } else {
                                    console.log(`ğŸ¤ ë„ˆë¬´ ì§§ì€ ìŒì„± - ë¬´ì‹œ (${vadStateRef.current.audioChunks.length} í”„ë ˆì„)`);
                                }

                                vadStateRef.current.isSpeaking = false;
                                vadStateRef.current.isSending = false;
                                vadStateRef.current.silenceFrames = 0;
                                vadStateRef.current.speechFrames = 0;
                                vadStateRef.current.audioChunks = [];
                                setIsUserTalking(false);
                            }
                        }
                    }
                };

                source.connect(processor);
                processor.connect(audioContextRef.current.destination);
                audioStreamRef.current = stream;
                audioSourceRef.current = source;
                audioProcessorRef.current = processor;
                setIsCallActive(true);
                console.log('âœ… í†µí™” ì‹œì‘ (ë¡œì»¬ VAD í™œì„±í™”)');
            } catch (error) {
                console.error('âŒ ë§ˆì´í¬ ì˜¤ë¥˜:', error);
                alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
                navigate('/app/home');
            }
        };

        initCall();
    }, [location.state, character, politeness, navigate]);

    // WebSocket ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆ
    useEffect(() => {
        const socket = getAiSocket();
        if (!socket) return;

        const messageHandler = async (event) => {
            if (typeof event.data === 'string') {
                const data = JSON.parse(event.data);

                // audio_start/audio_end ì²˜ë¦¬
                if (data.type === 'audio_start') {
                    isReceivingAudioRef.current = true;
                    audioBufferRef.current = [];
                    console.log(`ğŸµ ì˜¤ë””ì˜¤ ìˆ˜ì‹  ì‹œì‘ (${data.size} bytes ì˜ˆìƒ)`);
                } else if (data.type === 'audio_end') {
                    isReceivingAudioRef.current = false;
                    if (audioBufferRef.current && audioBufferRef.current.length > 0) {
                        const totalLength = audioBufferRef.current.reduce((sum, chunk) => sum + chunk.byteLength, 0);
                        console.log(`ğŸµ ì˜¤ë””ì˜¤ ìˆ˜ì§‘ ì™„ë£Œ: ${audioBufferRef.current.length}ê°œ ì²­í¬, ì´ ${totalLength} bytes`);

                        const combinedBuffer = new Uint8Array(totalLength);
                        let offset = 0;
                        for (const chunk of audioBufferRef.current) {
                            const chunkArray = chunk instanceof ArrayBuffer ? new Uint8Array(chunk) : chunk;
                            combinedBuffer.set(chunkArray, offset);
                            offset += chunkArray.length;
                        }
                        await playAudio(combinedBuffer.buffer);
                        audioBufferRef.current = null;
                    }
                } else {
                    handleMessage(data);
                }
            } else if (event.data instanceof Blob || event.data instanceof ArrayBuffer || event.data instanceof Uint8Array) {
                const buffer = event.data instanceof Blob ? await event.data.arrayBuffer() :
                    (event.data instanceof ArrayBuffer ? event.data : event.data.buffer);

                if (isReceivingAudioRef.current) {
                    audioBufferRef.current.push(buffer);
                    console.log(`ğŸ“¥ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ : ${buffer.byteLength} bytes (ì´ ${audioBufferRef.current.length}ê°œ)`);
                } else {
                    console.log(`ğŸ“¥ ì˜¤ë””ì˜¤ ì¦‰ì‹œ ì¬ìƒ: ${buffer.byteLength} bytes`);
                    await playAudio(buffer);
                }
            }
        };

        socket.onmessage = messageHandler;

        return () => {
            socket.onmessage = null;
        };
    }, [handleMessage, playAudio]);

    // isTalking ìƒíƒœì— ë”°ë¼ video ì¬ìƒ/ì •ì§€
    useEffect(() => {
        if (!videoRef.current) return;

        if (isTalking && !isUserTalking) {
            videoRef.current.play().catch((e) => {
                console.log('Video play failed:', e);
            });
        } else {
            videoRef.current.pause();
        }
    }, [isTalking, isUserTalking]);

    const handleEndCall = useCallback(() => {
        console.log('ğŸ“´ í†µí™” ì¢…ë£Œ');

        // VAD ìƒíƒœ ì´ˆê¸°í™”
        vadStateRef.current = {
            isSpeaking: false,
            silenceFrames: 0,
            speechFrames: 0,
            preRollBuffer: [],
            isSending: false,
            audioChunks: []
        };

        if (audioProcessorRef.current) {
            audioProcessorRef.current.disconnect();
            audioProcessorRef.current = null;
        }
        if (audioSourceRef.current) {
            audioSourceRef.current.disconnect();
            audioSourceRef.current = null;
        }
        if (audioStreamRef.current) {
            audioStreamRef.current.getTracks().forEach(track => track.stop());
            audioStreamRef.current = null;
        }

        endCall();
        setIsTalking(false);
        setIsCallActive(false);
        navigate('/app/home');
    }, [navigate]);

    // í˜ì´ì§€ ì–¸ë¡œë“œ ì‹œ ì •ë¦¬
    useEffect(() => {
        const handleBeforeUnload = () => {
            if (isCallActive) {
                handleEndCall();
            }
        };

        window.addEventListener('beforeunload', handleBeforeUnload);
        return () => {
            window.removeEventListener('beforeunload', handleBeforeUnload);
            if (isCallActive) {
                handleEndCall();
            }
        };
    }, [isCallActive, handleEndCall]);

    return (
        <Flex minH="100vh" align="center" justify="center" bg={isHighContrast ? '#000000' : 'white'} px={3}>
            {/* ë©”ì¸ ë¡œê·¸ì¸ ì¹´ë“œ */}
            <Box p={{ base: 5, md: 14 }} w="full" maxW="530px">
                <VStack spacing={6} align="stretch">
                    {/* ìºë¦­í„° ì˜ì—­ */}
                    <MotionBox
                        initial={{ scale: 0.8, opacity: 0 }}
                        animate={{ scale: 1, opacity: 1 }}
                        transition={{ duration: 0.5 }}
                        w="100%"
                        h="450px"
                        display="flex"
                        alignItems="center"
                        justifyContent="center"
                        overflow="hidden"
                        borderRadius="15px"
                        position="relative"
                    >
                        {/* video íƒœê·¸ë¡œ webm ì¬ìƒ ì œì–´ */}
                        <Box
                            as="video"
                            ref={videoRef}
                            src={character.characterType === 'dabok' ? DabokVideo : DajeongVideo}
                            loop
                            muted
                            playsInline
                            w="100%"
                            h="70%"
                            objectFit="cover"
                            onError={(e) => {
                                console.error('Video ë¡œë“œ ì‹¤íŒ¨:', e.target.src);
                            }}
                        />

                        {/* ìƒíƒœ í‘œì‹œ ë°°ì§€ */}
                        <HStack
                            position="absolute"
                            top="15px"
                            right="15px"
                            spacing={2}
                        >
                            {isUserTalking && (
                                <Badge
                                    colorScheme="blue"
                                    fontSize="md"
                                    px={3}
                                    py={1}
                                    borderRadius="full"
                                >
                                    ğŸ¤ ë§í•˜ëŠ” ì¤‘
                                </Badge>
                            )}
                            {isTalking && (
                                <Badge
                                    colorScheme="green"
                                    fontSize="md"
                                    px={3}
                                    py={1}
                                    borderRadius="full"
                                >
                                    ğŸ”Š AI ì‘ë‹µ ì¤‘
                                </Badge>
                            )}
                        </HStack>
                    </MotionBox>

                    {/* í˜„ì¬ ìë§‰ */}
                    <Box mt={2}>
                        <AnimatePresence mode="wait">
                            <MotionText
                                key={currentSubtitle}
                                initial={{ opacity: 0, y: 20 }}
                                animate={{ opacity: 1, y: 0 }}
                                exit={{ opacity: 0, y: -20 }}
                                transition={{ duration: 0.3 }}
                                fontSize={fs}
                                fontWeight="700"
                                color={isHighContrast ? '#FFFFFF' : '#000000'}
                                textAlign="center"
                                py={5}
                                borderRadius="15px"
                                minH="90px"
                                display="flex"
                                alignItems="center"
                                justifyContent="center"
                                w="full"
                            >
                                {currentSubtitle}
                            </MotionText>
                        </AnimatePresence>
                    </Box>

                    {/* í†µí™” ì¢…ë£Œ ë²„íŠ¼ */}
                    <Button
                        w="full"
                        bg={isHighContrast ? '#FFD700' : '#F44336'}
                        color={isHighContrast ? '#000000' : 'white'}
                        onClick={handleEndCall}
                        fontSize={fs}
                        fontWeight="700"
                        height={callBtnH}
                        borderRadius="15px"
                        border={isHighContrast ? '3px solid white' : 'none'}
                        boxShadow="0 4px 14px rgba(244, 67, 54, 0.3)"
                        mt={2}
                        _hover={{
                            bg: isHighContrast ? '#FFEB3B' : '#D32F2F',
                            transform: 'translateY(-2px)',
                            boxShadow: isHighContrast
                                ? '0 6px 20px rgba(255, 215, 0, 0.4)'
                                : '0 6px 20px rgba(244, 67, 54, 0.4)',
                        }}
                        _active={{
                            bg: isHighContrast ? '#FFC107' : '#C62828',
                            transform: 'translateY(0)',
                        }}
                        transition="all 0.2s"
                    >
                        í†µí™” ì¢…ë£Œ
                    </Button>
                </VStack>
            </Box>
        </Flex>
    );
}

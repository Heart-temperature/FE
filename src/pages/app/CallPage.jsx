import React, { useState, useEffect, useRef } from 'react';
import { Button, Flex, Text, VStack, Box, Image, Divider } from '@chakra-ui/react';
import { motion, AnimatePresence } from 'framer-motion';
import { useNavigate, useLocation } from 'react-router-dom';

import DajeongLogo from '../../assets/image.png';
import DabokVideo from '../../video/dabok.webm';
import DajeongVideo from '../../video/dajeung.webm';
import useAppSettings from '../../hooks/useAppSettings';

import { endCall, startCall } from '../../api/callAPI';
import { getAiSocket } from '../../api/aiSocket';

const MotionBox = motion(Flex);
const MotionText = motion(Text);

export default function CallPage() {
    const navigate = useNavigate();
    const location = useLocation();

    const { fontSizeLevel, setFontSizeLevel, isHighContrast, toggleHighContrast, fs, callBtnH } = useAppSettings();

    const [isTalking, setIsTalking] = useState(false); // AIê°€ ë§í•˜ëŠ” ì¤‘
    const [isUserSpeaking, setIsUserSpeaking] = useState(false); // ì‚¬ìš©ìê°€ ë§í•˜ëŠ” ì¤‘
    const [currentSubtitle, setCurrentSubtitle] = useState('í†µí™” ì—°ê²° ì¤‘...');
    const [aiMessages, setAiMessages] = useState([]);

    const videoRef = useRef(null); // video íƒœê·¸ ref
    const audioStreamRef = useRef(null); // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ref
    const audioContextRef = useRef(null); // AudioContext ref
    const analyserRef = useRef(null); // AnalyserNode ref
    const processorRef = useRef(null); // ScriptProcessorNode ref
    const audioBufferRef = useRef([]); // ì˜¤ë””ì˜¤ ë²„í¼
    const silenceStartTimeRef = useRef(null); // ì¹¨ë¬µ ì‹œì‘ ì‹œê°„
    const vadStateRef = useRef('idle'); // VAD ìƒíƒœ: idle, speaking, silence
    const aiSpeakingRef = useRef(false); // AI ë§í•˜ëŠ” ì¤‘ (VAD ë¹„í™œì„±í™”)
    const audioChunkCountRef = useRef(0); // ì˜¤ë””ì˜¤ ì²­í¬ ì¹´ìš´í„°
    const rmsLogIntervalRef = useRef(0); // RMS ë¡œê¹… ê°„ê²© ì¹´ìš´í„°

    // VAD ì„¤ì •
    const VAD_THRESHOLD = 0.005; // ìŒì„± ê°ì§€ ì„ê³„ê°’ (ë” ë¯¼ê°í•˜ê²Œ ì¡°ì •)
    const SILENCE_DURATION = 1500; // ì¹¨ë¬µ ì§€ì† ì‹œê°„ (ms) - 1.5ì´ˆ ì¹¨ë¬µì´ë©´ ì „ì†¡
    const MIN_AUDIO_LENGTH = 10; // ìµœì†Œ ì˜¤ë””ì˜¤ í¬ê¸° (ë…¸ì´ì¦ˆ í•„í„°ë§)

    // ì „ë‹¬ë°›ì€ ìºë¦­í„° ì •ë³´
    const character = location.state?.character || {
        name: 'ë‹¤ì •ì´',
        characterType: 'dajeong',
        color: '#2196F3',
    };

    // í†µí™” ì‹œì‘ ì‹œ API í˜¸ì¶œ ë° ë§ˆì´í¬ ì‹œì‘
    useEffect(() => {
        let isInitialized = false;

        const initCall = async () => {
            if (location.state && !isInitialized) {
                isInitialized = true;
                const { character, politeness } = location.state;

                console.log('='.repeat(50));
                console.log('ğŸ¬ í†µí™” ì´ˆê¸°í™” ì‹œì‘');
                console.log('='.repeat(50));

                // í†µí™” ì‹œì‘ API í˜¸ì¶œ (WebSocket ì—°ê²° í¬í•¨)
                await startCall(character, politeness);

                // WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ ë“±ë¡
                setupWebSocketHandler();

                // ë§ˆì´í¬ ì‹œì‘
                startMicrophone();

                console.log('='.repeat(50));
                console.log('âœ… í†µí™” ì´ˆê¸°í™” ì™„ë£Œ');
                console.log('='.repeat(50));
            }
        };

        initCall();

        // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
        return () => {
            stopMicrophone();
        };
    }, []); // ë¹ˆ ë°°ì—´ë¡œ ë³€ê²½ - í•œ ë²ˆë§Œ ì‹¤í–‰

    // ë§ˆì´í¬ ì‹œì‘ í•¨ìˆ˜ (VAD í¬í•¨)
    const startMicrophone = async () => {
        try {
            console.log('ğŸ¤ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘...');

            // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioStreamRef.current = stream;

            // AudioContext ìƒì„±
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            audioContextRef.current = audioContext;

            // ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ìƒì„±
            const source = audioContext.createMediaStreamSource(stream);

            // AnalyserNode ìƒì„± (ë³¼ë¥¨ ë¶„ì„ìš©)
            const analyser = audioContext.createAnalyser();
            analyser.fftSize = 2048;
            analyserRef.current = analyser;

            // ScriptProcessorNode ìƒì„± (ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬ìš©)
            const processor = audioContext.createScriptProcessor(4096, 1, 1);
            processorRef.current = processor;

            // ì˜¤ë””ì˜¤ ì²˜ë¦¬
            processor.onaudioprocess = (e) => {
                const inputData = e.inputBuffer.getChannelData(0);

                // ë³¼ë¥¨ ê³„ì‚° (RMS)
                let sum = 0;
                for (let i = 0; i < inputData.length; i++) {
                    sum += inputData[i] * inputData[i];
                }
                const rms = Math.sqrt(sum / inputData.length);

                // RMS ê°’ì„ ì£¼ê¸°ì ìœ¼ë¡œ ë¡œê¹… (50ë²ˆì— í•œ ë²ˆ)
                rmsLogIntervalRef.current++;
                if (rmsLogIntervalRef.current % 50 === 0) {
                    console.log(`ğŸ“Š RMS: ${rms.toFixed(6)} | ì„ê³„ê°’: ${VAD_THRESHOLD} | AI ë§í•˜ëŠ” ì¤‘: ${aiSpeakingRef.current} | VAD ìƒíƒœ: ${vadStateRef.current}`);
                }

                // AIê°€ ë§í•˜ëŠ” ì¤‘ì´ë©´ VAD ë¹„í™œì„±í™”
                if (aiSpeakingRef.current) {
                    // ì¹¨ë¬µ ì‹œì‘ ì‹œê°„ ì´ˆê¸°í™”
                    if (silenceStartTimeRef.current !== null) {
                        console.log('ğŸ¤– AI ë§í•˜ëŠ” ì¤‘ - VAD ë¹„í™œì„±í™”');
                        silenceStartTimeRef.current = null;
                        vadStateRef.current = 'idle';
                        setIsUserSpeaking(false);
                    }
                    return;
                }

                const now = Date.now();

                // VAD ë¡œì§
                if (rms > VAD_THRESHOLD) {
                    // ìŒì„± ê°ì§€
                    if (vadStateRef.current === 'idle') {
                        console.log('='.repeat(50));
                        console.log('ğŸ¤ ìŒì„± ê°ì§€ ì‹œì‘');
                        console.log('   RMS ê°’:', rms.toFixed(4));
                        console.log('   ì„ê³„ê°’:', VAD_THRESHOLD);
                        vadStateRef.current = 'speaking';
                        setIsUserSpeaking(true);
                        audioBufferRef.current = []; // ë²„í¼ ì´ˆê¸°í™”
                        audioChunkCountRef.current = 0;
                    }

                    // ì¹¨ë¬µ ì‹œì‘ ì‹œê°„ ì´ˆê¸°í™” (ìŒì„±ì´ ë‹¤ì‹œ ê°ì§€ë¨)
                    if (silenceStartTimeRef.current !== null) {
                        silenceStartTimeRef.current = null;
                        if (vadStateRef.current === 'silence') {
                            console.log('ğŸ¤ ì¹¨ë¬µ ì¤‘ë‹¨ - ë‹¤ì‹œ ë§í•˜ê¸° ì‹œì‘');
                            vadStateRef.current = 'speaking';
                        }
                    }

                    // ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë²„í¼ì— ì €ì¥
                    const int16Data = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }
                    audioBufferRef.current.push(int16Data);
                    audioChunkCountRef.current++;

                    // ì²« ë²ˆì§¸ ì²­í¬ ë˜ëŠ” 50ë²ˆì§¸ë§ˆë‹¤ ë¡œê·¸
                    if (audioChunkCountRef.current === 1 || audioChunkCountRef.current % 50 === 0) {
                        console.log(`ğŸ”Š ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì§‘: ${int16Data.length} samples (ì²­í¬ #${audioChunkCountRef.current})`);
                    }
                } else {
                    // ì¹¨ë¬µ ê°ì§€
                    if (vadStateRef.current === 'speaking') {
                        // ì¹¨ë¬µ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                        if (silenceStartTimeRef.current === null) {
                            silenceStartTimeRef.current = now;
                            vadStateRef.current = 'silence';
                            console.log('ğŸ”‡ ì¹¨ë¬µ ê°ì§€ ì‹œì‘');
                            console.log('   RMS ê°’:', rms.toFixed(4));
                            console.log('   ëŒ€ê¸° ì‹œê°„:', SILENCE_DURATION, 'ms');
                        }
                    }

                    // ì¹¨ë¬µì´ ì§€ì†ë˜ëŠ”ì§€ í™•ì¸
                    if (vadStateRef.current === 'silence' && silenceStartTimeRef.current !== null) {
                        const silenceDuration = now - silenceStartTimeRef.current;

                        // ì¹¨ë¬µ ì§€ì† ì‹œê°„ ì²´í¬ (100msë§ˆë‹¤ ë¡œê·¸)
                        if (silenceDuration % 500 < 100) {
                            console.log(`â±ï¸ ì¹¨ë¬µ ì§€ì†: ${silenceDuration}ms / ${SILENCE_DURATION}ms`);
                        }

                        if (silenceDuration >= SILENCE_DURATION) {
                            console.log('='.repeat(50));
                            console.log('ğŸ“¤ ì¹¨ë¬µ ì§€ì† ì‹œê°„ ì´ˆê³¼ - ì˜¤ë””ì˜¤ ì „ì†¡');
                            console.log('   ì¹¨ë¬µ ì§€ì†:', silenceDuration, 'ms');
                            console.log('   ìˆ˜ì§‘ëœ ì²­í¬:', audioChunkCountRef.current);
                            sendAudioBuffer();

                            // ìƒíƒœ ì´ˆê¸°í™”
                            vadStateRef.current = 'idle';
                            setIsUserSpeaking(false);
                            audioBufferRef.current = [];
                            audioChunkCountRef.current = 0;
                            silenceStartTimeRef.current = null;
                        }
                    }
                }
            };

            // ì—°ê²°
            source.connect(analyser);
            analyser.connect(processor);
            processor.connect(audioContext.destination);

            console.log('='.repeat(50));
            console.log('âœ… ë§ˆì´í¬ ì‹œì‘ ì™„ë£Œ (VAD í™œì„±í™”)');
            console.log('   ì„ê³„ê°’:', VAD_THRESHOLD);
            console.log('   ì¹¨ë¬µ ì§€ì† ì‹œê°„:', SILENCE_DURATION, 'ms');
            console.log('='.repeat(50));
        } catch (error) {
            console.error('âŒ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì‹¤íŒ¨:', error);
            alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
        }
    };

    // ì˜¤ë””ì˜¤ ë²„í¼ ì „ì†¡
    const sendAudioBuffer = () => {
        if (audioBufferRef.current.length === 0) {
            console.log('âš ï¸ ì „ì†¡í•  ì˜¤ë””ì˜¤ ì—†ìŒ (ë²„í¼ ë¹„ì–´ìˆìŒ)');
            return;
        }

        const socket = getAiSocket();
        if (!socket || socket.readyState !== WebSocket.OPEN) {
            console.error('âŒ WebSocket ì—°ê²° ì•ˆ ë¨');
            console.error('   ìƒíƒœ:', socket ? socket.readyState : 'null');
            return;
        }

        try {
            // ë²„í¼ë¥¼ í•˜ë‚˜ì˜ ArrayBufferë¡œ í•©ì¹˜ê¸°
            const totalLength = audioBufferRef.current.reduce((acc, arr) => acc + arr.length, 0);
            const mergedBuffer = new Int16Array(totalLength);
            let offset = 0;
            for (const buffer of audioBufferRef.current) {
                mergedBuffer.set(buffer, offset);
                offset += buffer.length;
            }

            // ë„ˆë¬´ ì‘ì€ ë°ì´í„°ëŠ” ë¬´ì‹œ (ë…¸ì´ì¦ˆ)
            if (mergedBuffer.length < MIN_AUDIO_LENGTH) {
                console.log('âš ï¸ ì˜¤ë””ì˜¤ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ (ë…¸ì´ì¦ˆë¡œ íŒë‹¨):', mergedBuffer.length, 'samples');
                return;
            }

            // Blobìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì „ì†¡
            const blob = new Blob([mergedBuffer.buffer], { type: 'audio/webm' });

            console.log('='.repeat(50));
            console.log('ğŸ“¤ AI ì„œë²„ë¡œ ì˜¤ë””ì˜¤ ì „ì†¡');
            console.log('   í¬ê¸°:', blob.size, 'bytes');
            console.log('   ìƒ˜í”Œ ìˆ˜:', mergedBuffer.length);
            console.log('   ì²­í¬ ìˆ˜:', audioBufferRef.current.length);

            socket.send(blob);

            console.log('âœ… ì˜¤ë””ì˜¤ ì „ì†¡ ì™„ë£Œ');
            console.log('='.repeat(50));
        } catch (error) {
            console.error('âŒ ì˜¤ë””ì˜¤ ì „ì†¡ ì‹¤íŒ¨:', error);
        }
    };

    // ë§ˆì´í¬ ì¤‘ì§€ í•¨ìˆ˜
    const stopMicrophone = () => {
        console.log('='.repeat(50));
        console.log('ğŸ¤ ë§ˆì´í¬ ì¤‘ì§€ ì‹œì‘...');

        // ì¹¨ë¬µ ì‹œì‘ ì‹œê°„ ì´ˆê¸°í™”
        silenceStartTimeRef.current = null;

        // ScriptProcessor ì •ë¦¬
        if (processorRef.current) {
            try {
                processorRef.current.disconnect();
                processorRef.current.onaudioprocess = null;
                processorRef.current = null;
                console.log('   âœ“ ScriptProcessor ì •ë¦¬');
            } catch (e) {
                console.warn('   âš ï¸ ScriptProcessor ì •ë¦¬ ì¤‘ ì˜¤ë¥˜:', e);
            }
        }

        // Analyser ì •ë¦¬
        if (analyserRef.current) {
            try {
                analyserRef.current.disconnect();
                analyserRef.current = null;
                console.log('   âœ“ Analyser ì •ë¦¬');
            } catch (e) {
                console.warn('   âš ï¸ Analyser ì •ë¦¬ ì¤‘ ì˜¤ë¥˜:', e);
            }
        }

        // AudioContext ì •ë¦¬
        if (audioContextRef.current) {
            try {
                audioContextRef.current.close();
                audioContextRef.current = null;
                console.log('   âœ“ AudioContext ì •ë¦¬');
            } catch (e) {
                console.warn('   âš ï¸ AudioContext ì •ë¦¬ ì¤‘ ì˜¤ë¥˜:', e);
            }
        }

        // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        if (audioStreamRef.current) {
            try {
                audioStreamRef.current.getTracks().forEach((track) => track.stop());
                audioStreamRef.current = null;
                console.log('   âœ“ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬');
            } catch (e) {
                console.warn('   âš ï¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜:', e);
            }
        }

        // ìƒíƒœ ì´ˆê¸°í™”
        vadStateRef.current = 'idle';
        audioBufferRef.current = [];
        audioChunkCountRef.current = 0;
        rmsLogIntervalRef.current = 0;
        setIsUserSpeaking(false);

        console.log('âœ… ë§ˆì´í¬ ì¤‘ì§€ ì™„ë£Œ');
        console.log('='.repeat(50));
    };

    // isTalking ìƒíƒœì— ë”°ë¼ video ì¬ìƒ/ì •ì§€
    useEffect(() => {
        if (!videoRef.current) return;

        if (isTalking) {
            // AIê°€ ë§í•  ë•Œ: ì¬ìƒ
            videoRef.current.play().catch((e) => {
                console.log('Video play failed:', e);
            });
        } else {
            // AI ë§ ì•ˆí•  ë•Œ: ì •ì§€
            videoRef.current.pause();
        }
    }, [isTalking]);

    // WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ ì„¤ì •
    const setupWebSocketHandler = () => {
        const socket = getAiSocket();
        if (!socket) {
            console.error('âŒ WebSocketì´ ì—†ìŠµë‹ˆë‹¤. í•¸ë“¤ëŸ¬ ë“±ë¡ ì‹¤íŒ¨');
            return;
        }

        console.log('='.repeat(50));
        console.log('ğŸ“¡ WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ ë“±ë¡');
        console.log('   WebSocket ìƒíƒœ:', socket.readyState, '(1=OPEN)');
        console.log('='.repeat(50));

        socket.onmessage = async (event) => {
            const data = event.data;
            console.log('ğŸ“¨ WebSocket ë©”ì‹œì§€ ìˆ˜ì‹  (íƒ€ì…:', typeof data, ')');

            // ì˜¤ë””ì˜¤ Blob ë©”ì‹œì§€ ì²˜ë¦¬
            if (data instanceof Blob) {
                console.log('='.repeat(50));
                console.log('ğŸ“¥ AI ì˜¤ë””ì˜¤ Blob ìˆ˜ì‹ ');
                console.log('   í¬ê¸°:', data.size, 'bytes');

                // ë„ˆë¬´ ì‘ì€ ë°ì´í„°ëŠ” ë¬´ì‹œ
                if (data.size < MIN_AUDIO_LENGTH) {
                    console.log('âš ï¸ ì˜¤ë””ì˜¤ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ (ë¬´ì‹œ)');
                    return;
                }

                // ì˜¤ë””ì˜¤ ì¬ìƒ
                const audioUrl = URL.createObjectURL(data);
                const audio = new Audio(audioUrl);

                // AIê°€ ë§í•˜ê¸° ì‹œì‘
                setIsTalking(true);
                aiSpeakingRef.current = true; // VAD ë¹„í™œì„±í™”
                console.log('ğŸ”Š AI ë§í•˜ê¸° ì‹œì‘ (VAD ë¹„í™œì„±í™”)');

                audio.onloadedmetadata = () => {
                    console.log('ğŸµ ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ');
                    console.log('   ì¬ìƒ ì‹œê°„:', audio.duration, 'ì´ˆ');
                };

                audio.onplay = () => {
                    console.log('â–¶ï¸ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ë¨');
                };

                audio.onplaying = () => {
                    console.log('â–¶ï¸ ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘...');
                };

                audio.onpause = () => {
                    console.log('â¸ï¸ ì˜¤ë””ì˜¤ ì¼ì‹œì •ì§€');
                };

                audio.onended = () => {
                    // AIê°€ ë§í•˜ê¸° ì¢…ë£Œ
                    setIsTalking(false);
                    aiSpeakingRef.current = false; // VAD ì¬í™œì„±í™”
                    URL.revokeObjectURL(audioUrl);
                    console.log('âœ… AI ë§í•˜ê¸° ì¢…ë£Œ (VAD ì¬í™œì„±í™”)');
                    console.log('='.repeat(50));
                };

                audio.onerror = (error) => {
                    console.error('âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', error);
                    console.error('   ì—ëŸ¬ ì½”ë“œ:', audio.error?.code);
                    console.error('   ì—ëŸ¬ ë©”ì‹œì§€:', audio.error?.message);
                    setIsTalking(false);
                    aiSpeakingRef.current = false;
                    URL.revokeObjectURL(audioUrl);
                };

                try {
                    const playPromise = audio.play();
                    console.log('ğŸ”Š audio.play() í˜¸ì¶œë¨');
                    await playPromise;
                    console.log('âœ… audio.play() Promise ì™„ë£Œ');
                } catch (error) {
                    console.error('âŒ audio.play() ì‹¤íŒ¨:', error);
                    console.error('   ì—ëŸ¬ ì´ë¦„:', error.name);
                    console.error('   ì—ëŸ¬ ë©”ì‹œì§€:', error.message);
                    setIsTalking(false);
                    aiSpeakingRef.current = false;
                }

                return;
            }

            // JSON í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
            try {
                const msg = JSON.parse(data);
                const msgType = msg.type || 'unknown';
                console.log('ğŸ“© AI JSON ë©”ì‹œì§€ ìˆ˜ì‹ :', msgType, msg);

                setAiMessages((prev) => [...prev, msg]);

                // ìë§‰ ì—…ë°ì´íŠ¸
                if (msg.message || msg.text) {
                    setCurrentSubtitle(msg.message || msg.text);
                    console.log('   ìë§‰ ì—…ë°ì´íŠ¸:', msg.message || msg.text);
                }
            } catch (err) {
                console.warn('âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨:', data);
            }
        };

        socket.onerror = (error) => {
            console.error('âŒ WebSocket ì—ëŸ¬:', error);
        };

        socket.onclose = (event) => {
            console.log('ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ');
            console.log('   ì½”ë“œ:', event.code);
            console.log('   ì´ìœ :', event.reason);
        };
    };

    const handleEndCall = () => {
        console.log('ğŸ“ í†µí™” ì¢…ë£Œ ìš”ì²­');

        // ë§ˆì´í¬ ì¤‘ì§€
        stopMicrophone();

        // í†µí™” ì¢…ë£Œ API í˜¸ì¶œ
        endCall();
        setIsTalking(false);

        console.log('âœ… í†µí™” ì¢…ë£Œ ì™„ë£Œ');
        navigate('/app/home');
    };

    return (
        <Flex minH="100vh" align="center" justify="center" bg={isHighContrast ? '#000000' : 'white'} px={3}>
            {/* ë©”ì¸ ë¡œê·¸ì¸ ì¹´ë“œ */}
            <Box p={{ base: 5, md: 14 }} w="full" maxW="530px">
                <VStack spacing={6} align="stretch">
                    {/* ìºë¦­í„° ì˜ì—­ */}
                    <MotionBox
                        initial={{ scale: 0.8, opacity: 0 }}
                        animate={{ scale: 1, opacity: 1 }}
                        transition={{ duration: 0.5 }}
                        w="100%"
                        h="450px"
                        display="flex"
                        alignItems="center"
                        justifyContent="center"
                        overflow="hidden"
                        borderRadius="15px"
                    >
                        {/* video íƒœê·¸ë¡œ webm ì¬ìƒ ì œì–´ */}
                        <Box
                            as="video"
                            ref={videoRef}
                            src={character.characterType === 'dabok' ? DabokVideo : DajeongVideo}
                            loop
                            muted
                            playsInline
                            w="100%"
                            h="70%"
                            objectFit="cover"
                            onError={(e) => {
                                console.error('Video ë¡œë“œ ì‹¤íŒ¨:', e.target.src);
                            }}
                        />
                    </MotionBox>

                    {/* í˜„ì¬ ìë§‰ */}
                    <Box mt={2}>
                        <AnimatePresence mode="wait">
                            <MotionText
                                key={currentSubtitle}
                                initial={{ opacity: 0, y: 20 }}
                                animate={{ opacity: 1, y: 0 }}
                                exit={{ opacity: 0, y: -20 }}
                                transition={{ duration: 0.3 }}
                                fontSize={fs}
                                fontWeight="700"
                                color={isHighContrast ? '#FFFFFF' : '#000000'}
                                textAlign="center"
                                py={5}
                                borderRadius="15px"
                                minH="90px"
                                display="flex"
                                alignItems="center"
                                justifyContent="center"
                                w="full"
                            >
                                {currentSubtitle}
                                {isUserSpeaking && ' ğŸ¤'}
                            </MotionText>
                        </AnimatePresence>
                    </Box>

                    {/* í†µí™” ì¢…ë£Œ ë²„íŠ¼ */}
                    <Button
                        w="full"
                        bg={isHighContrast ? '#FFD700' : '#F44336'}
                        color={isHighContrast ? '#000000' : 'white'}
                        onClick={handleEndCall}
                        fontSize={fs}
                        fontWeight="700"
                        height={callBtnH}
                        borderRadius="15px"
                        border={isHighContrast ? '3px solid white' : 'none'}
                        boxShadow="0 4px 14px rgba(244, 67, 54, 0.3)"
                        mt={2}
                        _hover={{
                            bg: isHighContrast ? '#FFEB3B' : '#D32F2F',
                            transform: 'translateY(-2px)',
                            boxShadow: isHighContrast
                                ? '0 6px 20px rgba(255, 215, 0, 0.4)'
                                : '0 6px 20px rgba(244, 67, 54, 0.4)',
                        }}
                        _active={{
                            bg: isHighContrast ? '#FFC107' : '#C62828',
                            transform: 'translateY(0)',
                        }}
                        transition="all 0.2s"
                    >
                        í†µí™” ì¢…ë£Œ
                    </Button>
                </VStack>
            </Box>
        </Flex>
    );
}
